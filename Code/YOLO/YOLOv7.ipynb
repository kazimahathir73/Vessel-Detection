{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def preprocess_for_ddpm(image_path, img_size=256):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    tensor = transform(image).unsqueeze(0)\n",
        "    return tensor\n",
        "\n",
        "def preprocess_for_yolo(image_path, img_size=640):\n",
        "    image = cv2.imread(image_path)\n",
        "    h, w = image.shape[:2]\n",
        "    scale = img_size / max(h, w)\n",
        "    new_w, new_h = int(w * scale), int(h * scale)\n",
        "    resized = cv2.resize(image, (new_w, new_h))\n",
        "\n",
        "    top = (img_size - new_h) // 2\n",
        "    bottom = img_size - new_h - top\n",
        "    left = (img_size - new_w) // 2\n",
        "    right = img_size - new_w - left\n",
        "\n",
        "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(114, 114, 114))\n",
        "    return padded\n",
        "\n",
        "def preprocess_folder(folder_path, output_folder, ddpm=True, img_size=256):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            input_path = os.path.join(folder_path, filename)\n",
        "            if ddpm:\n",
        "                tensor = preprocess_for_ddpm(input_path, img_size)\n",
        "                torch.save(tensor, os.path.join(output_folder, filename.split('.')[0] + '.pt'))\n",
        "            else:\n",
        "                yolo_image = preprocess_for_yolo(input_path, img_size)\n",
        "                cv2.imwrite(os.path.join(output_folder, filename), yolo_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train.py --img-size 640 --batch-size 16 --epochs 50 --data /content/vessel_data/dataset.yaml --weights yolov7.pt --device 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
